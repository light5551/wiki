---
tags:
  - RL
  - offline-RL
  - online-RL
paper: https://sites.google.com/view/fastrlap
---

![[Pasted image 20231102182002.png]]

В статье предлагается решить задачу обучения агрессивному стилю вождению по датасету с различных роботов, где есть только медленное движение. В работе используется последовательность алгоритмов для обучения **[[IQL]]** и **[[RLPD]]** для offline и online RL, соответственно. Время на дообучение занимало ~**20** мин, за счет замораживания encoder'a. Checkpoint'ы которые генерируется во время движения агента не должны быть в поле видимости observation. Из интересного, action space имеет динамически границы, а именно - следующее действие не может отличать от предыдущего на коэффициент(гиперпараметр). В качестве входных данных используется RGB + вектор скорости (из колесной одометрии) + вектор ускорения с IMU + вектор до цели(до следующего checkpoint'a).  FSM состоит из состояний:
1. Политика выбирает действие
2. Pseudo-reset когда машинка врезалась -- начинает ехать назад, чтобы выбраться из терминального состояния
## Алгоритм
![[Pasted image 20231102182204.png]]